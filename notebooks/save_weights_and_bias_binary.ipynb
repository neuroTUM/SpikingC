{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import snntorch as snn\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "\n",
    "# Additional Imports\n",
    "import snntorch as snn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Dataset\n",
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tonic import DiskCachedDataset\n",
    "\n",
    "# Network\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import utils\n",
    "\n",
    "import torchvision.transforms as torchvision_transforms\n",
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([31, 128, 2, 34, 34])\n",
      "Targets shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Define sensor size for NMNIST dataset\n",
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "\n",
    "# Define transformations\n",
    "# Note: The use of torch.from_numpy is removed as Tonic's transforms handle conversion.\n",
    "transform = tonic.transforms.Compose([\n",
    "    transforms.Denoise(filter_time=10000),\n",
    "    transforms.ToFrame(sensor_size=sensor_size, time_window=10000),\n",
    "    # torchvision.transforms.RandomRotation is not directly applicable to event data.\n",
    "    # If rotation is needed, it should be done on the frames after conversion by ToFrame.\n",
    "])\n",
    "\n",
    "# Load NMNIST datasets without caching\n",
    "trainset = tonic.datasets.NMNIST(save_to='/home/copparihollmann/neuroTUM/DATASETS/data/', transform=transform, train=True)\n",
    "testset = tonic.datasets.NMNIST(save_to='/home/copparihollmann/neuroTUM/DATASETS/data', transform=transform, train=False)\n",
    "\n",
    "# Split trainset into training and validation datasets\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "train_dataset, val_dataset = random_split(trainset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training, validation, and testing\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "# Fetch a single batch from the train_loader to inspect the shape\n",
    "data, targets = next(iter(train_loader))\n",
    "print(f\"Data shape: {data.shape}\")  # Example output: torch.Size([batch_size, timesteps, channels, height, width])\n",
    "print(f\"Targets shape: {targets.shape}\")  # Example output: torch.Size([batch_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # SNN\n",
    "    \"threshold1\": 2.5,\n",
    "    \"threshold2\": 8.0,\n",
    "    \"threshold3\": 4.0,\n",
    "    \"threshold4\": 2.0,\n",
    "    \"beta\": 0.5,\n",
    "    \"num_steps\": 10,\n",
    "    \n",
    "    # SNN Dense Shape\n",
    "    \"dense1_input\": 2312,\n",
    "    \"num_classes\": 10,\n",
    "    \n",
    "\n",
    "    # Network\n",
    "    \"batch_norm\": True,\n",
    "    \"dropout\": 0.3,\n",
    "\n",
    "    # Hyper Params\n",
    "    \"lr\": 0.007,\n",
    "\n",
    "    # Early Stopping\n",
    "    \"min_delta\": 1e-6,\n",
    "    \"patience_es\": 20,\n",
    "\n",
    "    # Training\n",
    "    \"epochs\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN_tests(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super(SNN_tests, self).__init__()\n",
    "\n",
    "    # Initialize configuration parameters\n",
    "      # LIF\n",
    "    self.thresh1 = config[\"threshold1\"]\n",
    "    self.thresh2 = config[\"threshold2\"]\n",
    "    self.thresh3 = config[\"threshold3\"]\n",
    "    self.beta = config[\"beta\"]\n",
    "    self.num_steps = config[\"num_steps\"]\n",
    "\n",
    "      # Dense Shape\n",
    "    self.dense1_input = config[\"dense1_input\"]\n",
    "    self.num_classes = config[\"num_classes\"]\n",
    "\n",
    "      # Network Layers\n",
    "    self.fc1 = nn.Linear(self.dense1_input, self.dense1_input//4)\n",
    "    self.lif1 = snn.Leaky(beta=self.beta, threshold=self.thresh1)\n",
    "    \n",
    "    \n",
    "    self.fc2 = nn.Linear(self.dense1_input//4, self.dense1_input//8)\n",
    "    self.lif2 = snn.Leaky(beta=self.beta, threshold=self.thresh2)\n",
    "    \n",
    "    self.fc3 = nn.Linear(self.dense1_input//8, self.num_classes)\n",
    "    self.lif3 = snn.Leaky(beta=self.beta, threshold=self.thresh3)\n",
    "    \n",
    "    self.flatten = nn.Flatten()\n",
    "    \n",
    "    \n",
    "    # Forward Pass\n",
    "  def forward(self, inpt):\n",
    "    mem1 = self.lif1.init_leaky()\n",
    "    mem2 = self.lif2.init_leaky()\n",
    "    mem3 = self.lif3.init_leaky()\n",
    "\n",
    "    all_outputs = {layer: [] for layer in ['inputs', 'fc1_outputs', 'lif1_spikes', 'fc2_outputs', 'lif2_spikes', 'fc3_outputs', 'lif3_spikes', 'mem1', 'mem2', 'mem3']}\n",
    "    print(inpt.shape)\n",
    "    for step in range(inpt.shape[0]):  # assuming inpt shape is (batch, time, ...)\n",
    "        current_input = inpt[step, ...].to(device)\n",
    "        \n",
    "        current_input = self.flatten(current_input)\n",
    "\n",
    "        current1 = self.fc1(current_input)\n",
    "        spike1, mem1 = self.lif1(current1, mem1)\n",
    "        current2 = self.fc2(spike1)\n",
    "        spike2, mem2 = self.lif2(current2, mem2)\n",
    "        current3 = self.fc3(spike2)\n",
    "        spike3, mem3 = self.lif3(current3, mem3)\n",
    "\n",
    "        # Collect outputs for each step\n",
    "        all_outputs['inputs'].append(current_input.detach().cpu().numpy())\n",
    "        all_outputs['fc1_outputs'].append(current1.detach().cpu().numpy())\n",
    "        all_outputs['lif1_spikes'].append(spike1.detach().cpu().numpy())\n",
    "        all_outputs['fc2_outputs'].append(current2.detach().cpu().numpy())\n",
    "        all_outputs['lif2_spikes'].append(spike2.detach().cpu().numpy())\n",
    "        all_outputs['fc3_outputs'].append(current3.detach().cpu().numpy())\n",
    "        all_outputs['lif3_spikes'].append(spike3.detach().cpu().numpy())\n",
    "        all_outputs['mem1'].append(mem1.detach().cpu().numpy())\n",
    "        all_outputs['mem2'].append(mem2.detach().cpu().numpy())\n",
    "        all_outputs['mem3'].append(mem3.detach().cpu().numpy())\n",
    "\n",
    "    return all_outputs\n",
    "  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SNN_tests(config).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Intermediate results of the network for a fixed input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 1, 2, 34, 34])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_and_save_model_outputs(model_path, test_loader, device):\n",
    "    model = SNN_tests(config).to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Load the model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    # Grab a single sample from the loader\n",
    "    single_sample, _ = next(iter(test_loader))  # Adjust if your dataloader is different\n",
    "    single_sample = single_sample.to(device)\n",
    "\n",
    "    # Run the forward pass\n",
    "    layer_outputs = model(single_sample[:,0, ...].unsqueeze(1))  # Adjust slicing based on your data\n",
    "\n",
    "    # Save the outputs\n",
    "    save_layer_outputs(layer_outputs)\n",
    "\n",
    "def save_layer_outputs(layer_outputs):\n",
    "    base_dir = \"./intermediate_outputs\"\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    \n",
    "    for layer_name, timesteps_outputs in layer_outputs.items():\n",
    "        layer_dir = os.path.join(base_dir, layer_name)\n",
    "        if not os.path.exists(layer_dir):\n",
    "            os.makedirs(layer_dir)\n",
    "        \n",
    "        for step, output in enumerate(timesteps_outputs):\n",
    "            file_path = os.path.join(layer_dir, f\"{layer_name}_timestep_{step}.bin\")\n",
    "            with open(file_path, 'wb') as f:\n",
    "                pickle.dump(output, f)\n",
    "\n",
    "# Assuming the model and device are defined, and model's forward() is correctly returning layer outputs\n",
    "# Example Usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"/home/copparihollmann/neuroTUM/SpikingC/SpikingCpp/notebooks/best_SNN_model.pth\"\n",
    "load_and_save_model_outputs(model_path, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 1, 2, 34, 34])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "def generate_metadata_from_model(model_path, test_loader, device, base_dir=\"./metadata\"):\n",
    "    model = SNN_tests(config).to(device)  # Make sure SNN_tests and config are defined/imported correctly\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Create directory for metadata if it does not exist\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "\n",
    "    # Initialize metadata dictionary\n",
    "    metadata = {}\n",
    "\n",
    "    # Process only one batch from the test loader\n",
    "    single_sample, _ = next(iter(test_loader))\n",
    "    single_sample = single_sample.to(device)\n",
    "\n",
    "    # Forward pass to get the outputs\n",
    "    with torch.no_grad():\n",
    "        layer_outputs = model(single_sample[:, 0, ...].unsqueeze(1))  # Adjust based on your data's shape\n",
    "\n",
    "    # Iterate through each layer's outputs and save metadata\n",
    "    for layer_name, outputs in layer_outputs.items():\n",
    "        # Example structure: layer_name might be 'fc1', outputs might be a tensor or a list of tensors\n",
    "        if isinstance(outputs, list):\n",
    "            shapes = [output.shape for output in outputs]\n",
    "            dtypes = [str(output.dtype) for output in outputs]\n",
    "        else:\n",
    "            shapes = [outputs.shape]\n",
    "            dtypes = [str(outputs.dtype)]\n",
    "        \n",
    "        # Store metadata\n",
    "        metadata[layer_name] = {\n",
    "            'shapes': shapes,\n",
    "            'dtypes': dtypes\n",
    "        }\n",
    "\n",
    "    # Save metadata to a JSON file\n",
    "    metadata_path = os.path.join(base_dir, \"metadata.json\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "# Assuming the model and device are defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"/home/copparihollmann/neuroTUM/fix/SpikingCpp/notebooks/best_SNN_model.pth\"\n",
    "test_loader = test_loader\n",
    "generate_metadata_from_model(model_path, test_loader, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model weight and biases to binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights_and_biases_to_binary(model_path, save_directory=\"weights_and_bias_binary\"):\n",
    "    # Load the model's state dictionary\n",
    "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "\n",
    "    metadata = {}\n",
    "\n",
    "    # Save each weight and bias parameter to a separate binary file and record metadata\n",
    "    for name, param in state_dict.items():\n",
    "        if 'weight' in name or 'bias' in name:\n",
    "            file_path = os.path.join(save_directory, f\"{name.replace('.', '_')}.bin\")\n",
    "            metadata[name] = {\n",
    "                'shape': param.shape,\n",
    "                'dtype': str(param.dtype)\n",
    "            }\n",
    "            # Open the file in binary write mode and save the tensor data\n",
    "            with open(file_path, 'wb') as f:\n",
    "                numpy_array = param.numpy()\n",
    "                f.write(numpy_array.tobytes())\n",
    "\n",
    "    # Save metadata to a JSON file\n",
    "    with open(os.path.join(save_directory, \"metadata.json\"), 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "# Example usage\n",
    "model_path = \"/home/copparihollmann/neuroTUM/SpikingC/SpikingCpp/notebooks/best_SNN_model.pth\"\n",
    "save_weights_and_biases_to_binary(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromorphic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
